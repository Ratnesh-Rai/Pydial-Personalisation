# Error model: 30% error rate, DSTC2 confscorer, DSTC2 nbestgenerator
# User model: standard sampled params, sampled patience
# Masks: on

###### General parameters ######
[GENERAL]
singledomain = True 
tracedialog = 0
seed = 07051991

[exec_config]
configdir = _benchmarkpolicies
logfiledir = _benchmarklogs
numtrainbatches = 4
traindialogsperbatch = 1000
numbatchtestdialogs =  500
trainsourceiteration = 0
numtestdialogs =  500
trainerrorrate = 30
testerrorrate  = 30
testeverybatch = True
#deleteprevpolicy = True

[logging]
usecolor = False
screen_level = test
file_level = test
file = auto

###### Environment parameters ######

[agent]
maxturns = 25

[usermodel]
usenewgoalscenarios = True
oldstylepatience = False
patience = 4,6
configfile = config/sampledUM-multiple.cfg
upfrontKnowledgeLength = 2

[errormodel]
nbestsize = 5
confusionmodel = LevenshteinConfusions
nbestgeneratormodel = DSTC2NBestGenerator
confscorer = DSTC2
configfile = config/set3-ErrorModel.cfg


[summaryacts]
maxinformslots = 5
informmask = True
requestmask = True
informcountaccepted = 4
byemask = True

###### Evaluation parameters ######

[eval]
rewardvenuerecommended=0
penaliseallturns = True
wrongvenuepenalty = 0
notmentionedvaluepenalty = 0      
successmeasure = objective 
successreward = 20

###### Dialogue Manager parameters ######

# Uncomment for GP policy ##
[policy]
policydir = _benchmarkpolicies
belieftype = focus
useconfreq = False
learning = True
policytype = gp
startwithhello = False
inpolicyfile = auto
outpolicyfile = auto

[gppolicy]
kernel = polysort
use_upfront_knowledge = True

[gpsarsa]
random = False
scale = 3

###### DOMAIN ######
[GENERAL]
domains = Laptops11

